{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv OpenAI fastapi uvicorn nest_asyncio pydantic tiktoken --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"GILAS_API_KEY\"),\n",
    "    base_url=\"https://api.gilas.io/v1/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 16385\n",
    "max_tokens = 1000\n",
    "messages_formating_tokens = 20 # number of tokens used to format messages\n",
    "\n",
    "def get_completion(instruction, prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"system\", \"content\": instruction},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import random\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def generate_few_shots_instruction(basic_instruction, prompt):\n",
    "    prompt_tokens = num_tokens_from_string(prompt)\n",
    "    instruction = f\"{basic_instruction}\\n\"\n",
    "\n",
    "    file_path = \"few-shots.txt\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # remove the empty lines\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    # store samples in a list\n",
    "    samples = []\n",
    "    # read every two lines (EN, FA) together\n",
    "    for i in range(0, len(lines), 2):\n",
    "        if i + 1 < len(lines):\n",
    "            if \"English:\" not in lines[i].strip():\n",
    "                raise RuntimeError(f\"Line does not start with 'English: ', {lines[i]}\")\n",
    "            if \"Farsi:\" not in lines[i+1].strip():\n",
    "                raise RuntimeError(f\"Line does not start with 'Farsi: ', {lines[i+1]}\")\n",
    "            \n",
    "            sample = f\"{lines[i].strip()}\\n{lines[i + 1].strip()}\\n\"\n",
    "            samples.append(sample)\n",
    "\n",
    "    # randomize to allow model to see variety of samples, if samples are more than the context size\n",
    "    random.shuffle(samples)\n",
    "    for sample in samples:\n",
    "        new_instruction = instruction + f\"{sample}\\n\"\n",
    "        if num_tokens_from_string(new_instruction) > (context - (max_tokens + prompt_tokens + messages_formating_tokens)):\n",
    "            break\n",
    "        instruction = new_instruction\n",
    "    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_instruction = f\"\"\"\n",
    "You are an intelligent translator specializing in translating technical texts from English to Farsi. Please follow these steps to translate the provided English texts to Farsi:\n",
    "1. Thoroughly understand the given text.\n",
    "2. Translate the content into fluent Farsi, preserving the original structure and flow.\n",
    "3. Tailor the translation for software engineers by keeping the technical and programming terms in English, enclosed in backticks (e.g., `GPT-3`).\n",
    "4. You can include additional explanations in Farsi for clarity, if needed.\n",
    "5. If you encounter a block of text enclosed in triple backticks, do not translate it; keep it as it is in your translation.\n",
    "6. Review your translation to ensure you followed the steps. If the translated text is not fluent Farsi, revise it. \n",
    "7. Your output should only include the very final version and formatted translation. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_test_data():\n",
    "    file_path = \"test-data.txt\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    if not hasattr(get_next_test_data, \"current_index\"):\n",
    "        get_next_test_data.current_index = 0\n",
    "\n",
    "    while get_next_test_data.current_index < len(lines):\n",
    "        next_line = lines[get_next_test_data.current_index].strip()\n",
    "        get_next_test_data.current_index += 1\n",
    "        if next_line:\n",
    "            return f\"\"\"English: {next_line} \\n\n",
    "            Farsi: ?\n",
    "            \"\"\"\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shots_prompt(question):\n",
    "    _instruction = generate_few_shots_instruction(basic_instruction, question)   \n",
    "    return get_completion(_instruction, question)\n",
    "\n",
    "def zero_shot_prompt(question):\n",
    "    return get_completion(basic_instruction, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html_table(prompt, single_shot_response, few_shots_response):\n",
    "    # Initialize the table with headers if it's the first call\n",
    "    if not hasattr(generate_html_table, 'header_added'):\n",
    "        generate_html_table.html_content = \"<table>\\n<tr><th>English Text</th><th>Zero Shot Translation</th><th>Few Shots Translation</th><th>Manual Translation</th></tr>\\n\"\n",
    "        generate_html_table.header_added = True\n",
    "    else:\n",
    "        # Remove the closing </table> tag if it exists\n",
    "        if generate_html_table.html_content.endswith(\"</table>\"):\n",
    "            generate_html_table.html_content = generate_html_table.html_content[:-8]\n",
    "\n",
    "\n",
    "    prompt = prompt.replace(\"English:\", \"\").replace(\"Farsi: ?\", \"\").replace(\"Farsi:\", \"\")\n",
    "    few_shots_response = few_shots_response.replace(\"English:\", \"\").replace(\"Farsi: ?\", \"\").replace(\"Farsi:\", \"\")\n",
    "    single_shot_response = single_shot_response.replace(\"English:\", \"\").replace(\"Farsi: ?\", \"\").replace(\"Farsi:\", \"\")\n",
    "\n",
    "    # Append new row to the html content\n",
    "    generate_html_table.html_content += f\"\"\"\n",
    "    <tr>\n",
    "    <td>{prompt}</td>\n",
    "    <td><input type=\"checkbox\" class=\"single_shot\"><label dir=\"rtl\">{single_shot_response}</label></td>\n",
    "    <td><input type=\"checkbox\" class=\"few_shots\"><label dir=\"rtl\">{few_shots_response}</label></td>\n",
    "    <td><textarea rows=\"10\" cols=\"50\" dir=\"rtl\"></textarea></td>\n",
    "    </tr>\\n\"\"\"\n",
    "\n",
    "    # Re-add the closing </table> tag\n",
    "    generate_html_table.html_content += \"</table>\"\n",
    "\n",
    "    return generate_html_table.html_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def gen_prompt_response(sample):\n",
    "    # Run synchronous functions in separate threads\n",
    "    few_shot_future = asyncio.to_thread(few_shots_prompt, sample)\n",
    "    single_shot_future = asyncio.to_thread(zero_shot_prompt, sample)\n",
    "    # Wait for both to complete\n",
    "    few_shots_response, single_shot_response = await asyncio.gather(few_shot_future, single_shot_future)\n",
    "\n",
    "    # Generate the HTML table with the results\n",
    "    return generate_html_table(sample, single_shot_response, few_shots_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException, Request\n",
    "from fastapi.responses import HTMLResponse\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def prompt_endpoint():\n",
    "    html_table = \"\"\n",
    "    sample = get_next_test_data()\n",
    "    while sample:\n",
    "        html_table = await gen_prompt_response(sample)\n",
    "        sample = get_next_test_data()\n",
    "\n",
    "    js_script = \"\"\"\n",
    "    function sendPromptData() {\n",
    "    \n",
    "            const tableRows = document.querySelectorAll(\"table tr:not(:first-child)\");\n",
    "            const data = Array.from(tableRows).map(row => {\n",
    "                const inputText = row.cells[0].innerText;\n",
    "                const singleShotCheckbox = row.querySelector('.single_shot');\n",
    "                const fewShotsCheckbox = row.querySelector('.few_shots');\n",
    "                const textarea = row.querySelector('textarea');\n",
    "\n",
    "                let response = textarea.value;  // Default to textarea value\n",
    "                if (singleShotCheckbox.checked) {\n",
    "                response = singleShotCheckbox.nextElementSibling.innerText; // Get the label next to the checkbox\n",
    "                } else if (fewShotsCheckbox.checked) {\n",
    "                response = fewShotsCheckbox.nextElementSibling.innerText; // Get the label next to the checkbox\n",
    "                }\n",
    "\n",
    "                return { \"english\": inputText, \"farsi\": response };\n",
    "            });\n",
    "\n",
    "            var payload = { \"data\": data }\n",
    "            console.log(payload);\n",
    "\n",
    "            // Create the request\n",
    "            fetch('/rlhf', {\n",
    "                method: 'POST', \n",
    "                headers: {\n",
    "                    'Content-Type': 'application/json'\n",
    "                },\n",
    "                body: JSON.stringify(payload)\n",
    "            })\n",
    "            .then(response => response.json())\n",
    "            .then(data => {\n",
    "                console.log('Success:', data);\n",
    "                alert('Data sent successfully!');\n",
    "            })\n",
    "            .catch((error) => {\n",
    "                console.error('Error:', error);\n",
    "                alert('Failed to send data.');\n",
    "            });\n",
    "        }\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"<html>\n",
    "    <head><title>Prompt Results</title>\n",
    "    <script>\n",
    "            {js_script}\n",
    "    </script>\n",
    "    </head>\n",
    "    \n",
    "    <body> \n",
    "    <h2> How to use this tool </h2>\n",
    "    <p>\n",
    "    To utilize this Right-Left-Human-Feedback tool, you must either select one of the provided translations for the given English text by checking its checkbox or provide your own translation. <br/>\n",
    "    You can also skip some rows if needed. <br/> <br/>\n",
    "    Upon clicking the \"Submit Feedback\" button, your feedback is sent to the server and appended to the few-shots.txt file for future reference.\n",
    "    </p>\n",
    "    {html_table} \n",
    "    <br />\n",
    "    <br />\n",
    "    <button type=\"button\" onclick=\"sendPromptData()\">Submit Feedback</button>\n",
    "\n",
    "    </body></html>\"\"\"\n",
    "\n",
    "\n",
    "    return html_content\n",
    "\n",
    "# Define the data model for the payload\n",
    "class Entry(BaseModel):\n",
    "    english: str\n",
    "    farsi: str\n",
    "\n",
    "class Data(BaseModel):\n",
    "    data: List[Entry]\n",
    "\n",
    "@app.post(\"/rlhf\")\n",
    "async def receive_prompt(payload: Data):\n",
    "    try:\n",
    "        # update samples in the few-shots file\n",
    "        with open(\"few-shots.txt\", 'a') as file:\n",
    "            data = payload.model_dump()['data']\n",
    "            for item in data:\n",
    "                if len(item['farsi']) == 0:\n",
    "                    continue\n",
    "                output_string = f\"English: {item['english']}\\nFarsi: {item['farsi']}\\n\\n\"\n",
    "                file.write(output_string)\n",
    "\n",
    "        # delete the test entry from the test-data file\n",
    "        with open(\"test-data.txt\", 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        found = False\n",
    "        for line in lines:\n",
    "            for item in data:\n",
    "                if len(item['farsi']) > 0 and item['english'] in line:\n",
    "                    lines.remove(line)\n",
    "                    found = True\n",
    "\n",
    "        if not found:\n",
    "            return\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(\"test-data.txt\", 'w') as file:\n",
    "            file.writelines(lines)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "    \n",
    "# If using asyncio in Jupyter, apply the following:\n",
    "nest_asyncio.apply()\n",
    "\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"info\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
